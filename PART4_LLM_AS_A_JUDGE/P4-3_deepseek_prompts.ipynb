{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29fa971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import csv\n",
    "import re\n",
    "from random import randint\n",
    "import warnings\n",
    "import openai\n",
    "import yaml\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a4ea8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(yaml_path=\"P4-config.yaml\"):\n",
    "    with open(yaml_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "    \n",
    "config = load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc3e2873",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "\n",
    "client_deepseek = OpenAI(\n",
    "    api_key=os.getenv(\"DEEPSEEK_API_KEY\"),\n",
    "    base_url=\"https://api.deepseek.com\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3be67afa-327a-47a6-9835-db5a8dc4799a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL CHOICE\n",
    "model = \"llama\" # or llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "797b59b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model == \"biomistral\":\n",
    "    input_file_path = \"input_file_paths_biomistral\"\n",
    "    prompts_dir = \"prompts_dir_biomistral\"\n",
    "    output_dir = \"output_file_paths_biomistral\"\n",
    "\n",
    "elif model == \"llama\":\n",
    "    input_file_path = \"input_file_paths_llama\"\n",
    "    prompts_dir = \"prompts_dir_llama\"\n",
    "    output_dir = \"output_file_paths_llama\"\n",
    "\n",
    "    \n",
    "deepseek_prompt_dir = config[prompts_dir][\"deepseek_prompt_dir\"]\n",
    "basic_prompt_path = os.path.join(deepseek_prompt_dir, \"basic_realworld_test\")\n",
    "onco_prompt_path = os.path.join(deepseek_prompt_dir, \"onco_realworld_test\")\n",
    "reviewer_prompt_path = os.path.join(deepseek_prompt_dir, \"reviewer_realworld_test\")\n",
    "\n",
    "basic_filepath = basic_prompt_path +  '/pdsqi_input_to_llm_as_a_judge_zero_shot.csv'\n",
    "onco_filepath = onco_prompt_path +  '/pdsqi_input_to_llm_as_a_judge_zero_shot.csv'\n",
    "reviewer_filepath = reviewer_prompt_path +  '/pdsqi_input_to_llm_as_a_judge_zero_shot.csv'\n",
    "\n",
    "df_basic_prompts = pd.read_csv(basic_filepath)\n",
    "df_onco_prompts = pd.read_csv(onco_filepath)\n",
    "df_reviewer_prompts = pd.read_csv(reviewer_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1303de73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Here is your new role and persona:\\n        Yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Here is your new role and persona:\\n        Yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Here is your new role and persona:\\n        Yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Here is your new role and persona:\\n        Yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Here is your new role and persona:\\n        Yo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   record_id                                             prompt\n",
       "0          0  Here is your new role and persona:\\n        Yo...\n",
       "1          1  Here is your new role and persona:\\n        Yo...\n",
       "2          2  Here is your new role and persona:\\n        Yo...\n",
       "3          3  Here is your new role and persona:\\n        Yo...\n",
       "4          4  Here is your new role and persona:\\n        Yo..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_basic_prompts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c0aa502",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_basic = pd.read_csv(config[input_file_path][\"basic_realworld_test\"])\n",
    "df_onco = pd.read_csv(config[input_file_path][\"onco_realworld_test\"])\n",
    "df_reviewer = pd.read_csv(config[input_file_path][\"reviewer_realworld_test\"])\n",
    "\n",
    "# add index columns\n",
    "def add_index_column(df):\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={\"index\": \"record_id\"}, inplace=True)\n",
    "    return df\n",
    "\n",
    "df_basic = add_index_column(df_basic)\n",
    "df_onco = add_index_column(df_onco)\n",
    "df_reviewer = add_index_column(df_reviewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89eb6eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Receptor</th>\n",
       "      <th>PDB_ID</th>\n",
       "      <th>generated_report</th>\n",
       "      <th>prompt_tier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Metformin</td>\n",
       "      <td>Acetyl-CoA carboxylase 2</td>\n",
       "      <td>3FF6,3TDC,2X24,3JRX,3JRW,2HJW,4HQ6,5KKN,3GLK,3...</td>\n",
       "      <td>)&lt;Output&gt;\\n{{\\n  \"Mechanism\": \"&lt;Metformin targ...</td>\n",
       "      <td>basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Pioglitazone</td>\n",
       "      <td>Peroxisome proliferator-activated receptor gamma</td>\n",
       "      <td>3E00,3DZY,3DZU,7QB1,6L89,6K0T,6AD9,5HZC,5F9B,5...</td>\n",
       "      <td>)&lt;Output format&gt;\\n{{\\n  \"Mechanism\": \"&lt;Pioglit...</td>\n",
       "      <td>basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Alogliptin</td>\n",
       "      <td>Dipeptidyl peptidase 4</td>\n",
       "      <td>2QTB,2QT9,2BGR,2JID,3F8S,2QJR,3W2T,3VJM,3VJL,3...</td>\n",
       "      <td>)&lt;Output format&gt;\\n{{\\n  \"Mechanism\": \"&lt;Aloglip...</td>\n",
       "      <td>basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Linagliptin</td>\n",
       "      <td>Dipeptidyl peptidase 4</td>\n",
       "      <td>2QTB,2QT9,2BGR,2JID,3F8S,2QJR,3W2T,3VJM,3VJL,3...</td>\n",
       "      <td>)&lt;Output format&gt;\\n{{\\n  \"Mechanism\": \"&lt;Linagli...</td>\n",
       "      <td>basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Sitagliptin</td>\n",
       "      <td>Dipeptidyl peptidase 4</td>\n",
       "      <td>2QTB,2QT9,2BGR,2JID,3F8S,2QJR,3W2T,3VJM,3VJL,3...</td>\n",
       "      <td>)&lt;Output format&gt;\\n{{\\n  \"Mechanism\": \"&lt;Sitagli...</td>\n",
       "      <td>basic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   record_id          Drug                                          Receptor  \\\n",
       "0          0     Metformin                          Acetyl-CoA carboxylase 2   \n",
       "1          1  Pioglitazone  Peroxisome proliferator-activated receptor gamma   \n",
       "2          2    Alogliptin                            Dipeptidyl peptidase 4   \n",
       "3          3   Linagliptin                            Dipeptidyl peptidase 4   \n",
       "4          4   Sitagliptin                            Dipeptidyl peptidase 4   \n",
       "\n",
       "                                              PDB_ID  \\\n",
       "0  3FF6,3TDC,2X24,3JRX,3JRW,2HJW,4HQ6,5KKN,3GLK,3...   \n",
       "1  3E00,3DZY,3DZU,7QB1,6L89,6K0T,6AD9,5HZC,5F9B,5...   \n",
       "2  2QTB,2QT9,2BGR,2JID,3F8S,2QJR,3W2T,3VJM,3VJL,3...   \n",
       "3  2QTB,2QT9,2BGR,2JID,3F8S,2QJR,3W2T,3VJM,3VJL,3...   \n",
       "4  2QTB,2QT9,2BGR,2JID,3F8S,2QJR,3W2T,3VJM,3VJL,3...   \n",
       "\n",
       "                                    generated_report prompt_tier  \n",
       "0  )<Output>\\n{{\\n  \"Mechanism\": \"<Metformin targ...       basic  \n",
       "1  )<Output format>\\n{{\\n  \"Mechanism\": \"<Pioglit...       basic  \n",
       "2  )<Output format>\\n{{\\n  \"Mechanism\": \"<Aloglip...       basic  \n",
       "3  )<Output format>\\n{{\\n  \"Mechanism\": \"<Linagli...       basic  \n",
       "4  )<Output format>\\n{{\\n  \"Mechanism\": \"<Sitagli...       basic  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_basic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "298ca97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Summary</th>\n",
       "      <th>accurate</th>\n",
       "      <th>organized</th>\n",
       "      <th>comprehensible</th>\n",
       "      <th>succinct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Metformin</td>\n",
       "      <td>)&lt;Output&gt;\\n{{\\n  \"Mechanism\": \"&lt;Metformin targ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Pioglitazone</td>\n",
       "      <td>)&lt;Output format&gt;\\n{{\\n  \"Mechanism\": \"&lt;Pioglit...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Alogliptin</td>\n",
       "      <td>)&lt;Output format&gt;\\n{{\\n  \"Mechanism\": \"&lt;Aloglip...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Linagliptin</td>\n",
       "      <td>)&lt;Output format&gt;\\n{{\\n  \"Mechanism\": \"&lt;Linagli...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Sitagliptin</td>\n",
       "      <td>)&lt;Output format&gt;\\n{{\\n  \"Mechanism\": \"&lt;Sitagli...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   record_id          Drug                                            Summary  \\\n",
       "0          0     Metformin  )<Output>\\n{{\\n  \"Mechanism\": \"<Metformin targ...   \n",
       "1          1  Pioglitazone  )<Output format>\\n{{\\n  \"Mechanism\": \"<Pioglit...   \n",
       "2          2    Alogliptin  )<Output format>\\n{{\\n  \"Mechanism\": \"<Aloglip...   \n",
       "3          3   Linagliptin  )<Output format>\\n{{\\n  \"Mechanism\": \"<Linagli...   \n",
       "4          4   Sitagliptin  )<Output format>\\n{{\\n  \"Mechanism\": \"<Sitagli...   \n",
       "\n",
       "  accurate organized comprehensible succinct  \n",
       "0     None      None           None     None  \n",
       "1     None      None           None     None  \n",
       "2     None      None           None     None  \n",
       "3     None      None           None     None  \n",
       "4     None      None           None     None  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_scorefile(df, name):\n",
    "    scoreFile_name = f\"scoreFile_{name}\"\n",
    "    scoreFile_name = pd.DataFrame({\n",
    "        \"record_id\": df[\"record_id\"],\n",
    "        \"Drug\": df[\"Drug\"],\n",
    "        \"Summary\": df[\"generated_report\"],\n",
    "        \"accurate\": None,\n",
    "        \"organized\": None,\n",
    "        \"comprehensible\": None,\n",
    "        \"succinct\": None,\n",
    "    })\n",
    "    scoreFile_name.head()\n",
    "\n",
    "    return scoreFile_name\n",
    "\n",
    "basic_scorefile = create_scorefile(df_basic, \"basic\")\n",
    "onco_scorefile = create_scorefile(df_onco, \"onco\")\n",
    "reviewer_scorefile = create_scorefile(df_reviewer, \"reviewer\")\n",
    "\n",
    "basic_scorefile.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab565385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_deepseek_r1(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Call DeepSeek-R1 (deepseek-reasoner) and return the raw text output.\n",
    "    Raises an error if anything goes wrong or if the model returns empty text.\n",
    "    \"\"\"\n",
    "    if prompt is None or str(prompt).strip() == \"\":\n",
    "        raise ValueError(\"Prompt is empty or blank\")\n",
    "\n",
    "    try:\n",
    "        resp = client_deepseek.chat.completions.create(\n",
    "            model=\"deepseek-reasoner\",   # R1 reasoning model\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=6000,\n",
    "            temperature=1.0,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        # Do NOT silently swallow this – let it be visible\n",
    "        raise RuntimeError(f\"DeepSeek API call failed: {e}\")\n",
    "\n",
    "    # Inspect choices\n",
    "    if not resp.choices or resp.choices[0].message is None:\n",
    "        raise RuntimeError(f\"DeepSeek returned no choices: {resp}\")\n",
    "\n",
    "    content = resp.choices[0].message.content\n",
    "    if content is None:\n",
    "        raise RuntimeError(f\"DeepSeek returned None content: {resp}\")\n",
    "\n",
    "    content = str(content)\n",
    "    if not content.strip():\n",
    "        raise RuntimeError(f\"DeepSeek returned EMPTY content: {repr(content)}\\nFull response: {resp}\")\n",
    "\n",
    "    return content\n",
    "\n",
    "def parse_deepseek_output(text):\n",
    "    text = text.strip()\n",
    "    # extract JSON between <think> and </think>\n",
    "    match = re.search(r'<think>(.*?)</think>', text, re.DOTALL)\n",
    "    if not match:\n",
    "        return text  # return original text if no match\n",
    "    \n",
    "    json_part = match.group(1).strip()\n",
    "    return json.loads(json_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed1b603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rating(df, scoreFile):\n",
    "    raw_outputs = []\n",
    "    errors = []\n",
    "\n",
    "    # Make updates easier/faster by indexing scoreFile on record_id\n",
    "    if \"record_id\" not in scoreFile.columns:\n",
    "        raise ValueError(\"scoreFile is missing 'record_id' column\")\n",
    "    \n",
    "    scoreFile_indexed = scoreFile.set_index(\"record_id\")\n",
    "\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        record_id = row[\"record_id\"]\n",
    "        prompt = row[\"prompt\"]\n",
    "\n",
    "        # handle empty / NaN prompts\n",
    "        if prompt is None or (isinstance(prompt, float) and pd.isna(prompt)):\n",
    "            errors.append({\n",
    "                \"index\": i,\n",
    "                \"record_id\": record_id,\n",
    "                \"error\": \"Empty or NaN prompt\"\n",
    "            })\n",
    "            continue  # IMPORTANT: skip calling the model for this row\n",
    "\n",
    "        try:\n",
    "            raw = call_deepseek_r1(prompt)\n",
    "            parse = parse_deepseek_output(raw)\n",
    "            raw_outputs.append({\"record_id\": record_id, \"raw_output\": parse})\n",
    "\n",
    "            # Try to parse JSON\n",
    "            try:\n",
    "                scores = json.loads(raw)\n",
    "            except Exception as je:\n",
    "                errors.append({\n",
    "                    \"index\": i,\n",
    "                    \"record_id\": record_id,\n",
    "                    \"error\": f\"JSON parse failed: {je}\",\n",
    "                    \"raw_output\": raw,\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            # Update scoreFile_indexed with parsed scores\n",
    "            for col in [\"accurate\", \"organized\", \"comprehensible\", \"succinct\"]:\n",
    "                if col in scores:\n",
    "                    scoreFile_indexed.loc[record_id, col] = scores[col]\n",
    "\n",
    "        except Exception as e:\n",
    "            errors.append({\n",
    "                \"index\": i,\n",
    "                \"record_id\": record_id,\n",
    "                \"error\": f\"API call failed: {e}\",\n",
    "            })\n",
    "\n",
    "    # --- turn everything into DataFrames and RETURN them ---\n",
    "    updated_scores = scoreFile_indexed.reset_index()\n",
    "    raw_df = pd.DataFrame(raw_outputs)\n",
    "    errors_df = pd.DataFrame(errors)\n",
    "\n",
    "    return updated_scores, raw_df, errors_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f569a864",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [42:30<00:00, 87.96s/it] \n",
      "100%|██████████| 29/29 [42:40<00:00, 88.28s/it] \n",
      "100%|██████████| 29/29 [40:51<00:00, 84.52s/it]\n"
     ]
    }
   ],
   "source": [
    "basic_scores, basic_raw, basic_errors = extract_rating(\n",
    "    df_basic_prompts,\n",
    "    basic_scorefile\n",
    ")\n",
    "\n",
    "onco_scores, onco_raw, onco_errors = extract_rating(\n",
    "    df_onco_prompts,\n",
    "    onco_scorefile\n",
    "\n",
    ")\n",
    "\n",
    "reviewer_scores, reviewer_raw, reviewer_errors = extract_rating(\n",
    "    df_reviewer_prompts,\n",
    "    reviewer_scorefile\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc0825b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = config[output_dir][\"deepseek_ratings_output_dir\"]\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# create output directories for each evaluation set\n",
    "basic_output_path = os.path.join(output_path, \"basic_realworld_test\")\n",
    "os.makedirs(basic_output_path, exist_ok=True)\n",
    "onco_output_path = os.path.join(output_path, \"onco_realworld_test\")\n",
    "os.makedirs(onco_output_path, exist_ok=True)\n",
    "reviewer_output_path = os.path.join(output_path, \"reviewer_realworld_test\")\n",
    "os.makedirs(reviewer_output_path, exist_ok=True)\n",
    "\n",
    "# Save basic results\n",
    "basic_scores.to_csv(os.path.join(basic_output_path, \"deepseek_ratings_basic_realworld_test.csv\"), index=False)\n",
    "basic_raw.to_csv(os.path.join(basic_output_path, \"deepseek_raw_outputs_basic_realworld_test.csv\"), index=False)\n",
    "basic_errors.to_csv(os.path.join(basic_output_path, \"deepseek_errors_basic_realworld_test.csv\"), index=False)\n",
    "\n",
    "# Save onco results\n",
    "onco_scores.to_csv(os.path.join(onco_output_path, \"deepseek_ratings_onco_realworld_test.csv\"), index=False)\n",
    "onco_raw.to_csv(os.path.join(onco_output_path, \"deepseek_raw_outputs_onco_realworld_test.csv\"), index=False)\n",
    "onco_errors.to_csv(os.path.join(onco_output_path, \"deepseek_errors_onco_realworld_test.csv\"), index=False)\n",
    "\n",
    "# Save reviewer results\n",
    "reviewer_scores.to_csv(os.path.join(reviewer_output_path, \"deepseek_ratings_reviewer_realworld_test.csv\"), index=False)\n",
    "reviewer_raw.to_csv(os.path.join(reviewer_output_path, \"deepseek_raw_outputs_reviewer_realworld_test.csv\"), index=False)\n",
    "reviewer_errors.to_csv(os.path.join(reviewer_output_path, \"deepseek_errors_reviewer_realworld_test.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "439d037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RUBRICS = [\"accurate\", \"organized\", \"comprehensible\", \"succinct\"]\n",
    "\n",
    "def _strip_think_tags(s: str) -> str:\n",
    "    # Remove <think>...</think> and any similar XML-ish blocks\n",
    "    s = re.sub(r\"<think>.*?</think>\", \" \", s, flags=re.DOTALL | re.IGNORECASE)\n",
    "    return s\n",
    "\n",
    "def _extract_first_braced_object(s: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Extract the first {...} block using a simple brace-balancing scan.\n",
    "    This is much safer than regex for nested braces.\n",
    "    \"\"\"\n",
    "    if not s:\n",
    "        return None\n",
    "\n",
    "    start = s.find(\"{\")\n",
    "    if start == -1:\n",
    "        return None\n",
    "\n",
    "    depth = 0\n",
    "    for i in range(start, len(s)):\n",
    "        ch = s[i]\n",
    "        if ch == \"{\":\n",
    "            depth += 1\n",
    "        elif ch == \"}\":\n",
    "            depth -= 1\n",
    "            if depth == 0:\n",
    "                return s[start:i+1]\n",
    "\n",
    "    # Unbalanced braces (no closing '}')\n",
    "    return None\n",
    "\n",
    "def parse_deepseek_output(raw: str):\n",
    "    \"\"\"\n",
    "    Returns a dict with rubric keys if parse succeeds, else None.\n",
    "    \"\"\"\n",
    "    if raw is None or (isinstance(raw, float) and pd.isna(raw)):\n",
    "        return None\n",
    "\n",
    "    s = str(raw).strip()\n",
    "\n",
    "    # Normalize obvious formatting noise\n",
    "    s = s.replace(\"\\r\", \" \")\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "\n",
    "    # Remove think tags\n",
    "    s = _strip_think_tags(s)\n",
    "\n",
    "    # Try to grab the first JSON-like object\n",
    "    obj_txt = _extract_first_braced_object(s)\n",
    "    if obj_txt is None:\n",
    "        return None\n",
    "\n",
    "    # Attempt 1: strict JSON\n",
    "    try:\n",
    "        data = json.loads(obj_txt)\n",
    "    except Exception:\n",
    "        # Attempt 2: fix common issues then json.loads\n",
    "        fixed = obj_txt\n",
    "\n",
    "        # remove trailing commas before } or ]\n",
    "        fixed = re.sub(r\",\\s*([}\\]])\", r\"\\1\", fixed)\n",
    "\n",
    "        # convert single quotes to double quotes (common DeepSeek issue)\n",
    "        # NOTE: this is a heuristic; good enough for simple dicts like yours\n",
    "        fixed = re.sub(r\"(?<!\\\\)'\", '\"', fixed)\n",
    "\n",
    "        try:\n",
    "            data = json.loads(fixed)\n",
    "        except Exception:\n",
    "            # Attempt 3: python literal eval (handles single quotes naturally)\n",
    "            try:\n",
    "                data = ast.literal_eval(obj_txt)\n",
    "            except Exception:\n",
    "                return None\n",
    "\n",
    "    if not isinstance(data, dict):\n",
    "        return None\n",
    "\n",
    "    # Normalize keys + values\n",
    "    out = {}\n",
    "    for k in RUBRICS:\n",
    "        v = data.get(k, data.get(k.capitalize(), None))\n",
    "        if v is None:\n",
    "            out[k] = None\n",
    "            continue\n",
    "\n",
    "        # convert \"5\", 5, 5.0 -> float/int\n",
    "        try:\n",
    "            v_num = float(v)\n",
    "            # if it's an integer-like float, store as int (optional)\n",
    "            out[k] = int(v_num) if v_num.is_integer() else v_num\n",
    "        except Exception:\n",
    "            out[k] = None\n",
    "\n",
    "    # If all are missing, treat as parse fail\n",
    "    if all(out[k] is None for k in RUBRICS):\n",
    "        return None\n",
    "\n",
    "    return out\n",
    "\n",
    "def clean_rawdf(raw_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = raw_df.copy()\n",
    "\n",
    "    parsed = df[\"raw_output\"].apply(parse_deepseek_output)\n",
    "\n",
    "    for rubric in RUBRICS:\n",
    "        df[rubric] = parsed.apply(lambda x: x.get(rubric) if isinstance(x, dict) else None)\n",
    "\n",
    "    # (Optional) keep a flag for debugging\n",
    "    df[\"parse_ok\"] = parsed.apply(lambda x: isinstance(x, dict))\n",
    "\n",
    "    # Light cleanup for display only (doesn't affect parsing anymore)\n",
    "    df[\"raw_output\"] = df[\"raw_output\"].astype(str).str.replace(r\"\\s+\", \" \", regex=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c682249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>raw_output</th>\n",
       "      <th>accurate</th>\n",
       "      <th>organized</th>\n",
       "      <th>comprehensible</th>\n",
       "      <th>succinct</th>\n",
       "      <th>parse_ok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>{\"accurate\": 2, \"organized\": 5, \"comprehensibl...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{'accurate': 2, 'organized': 5, 'comprehensibl...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>{\"accurate\": 5, \"organized\": 2, \"comprehensibl...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>{'accurate': 4, 'organized': 5, 'comprehensibl...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>{'accurate': 2, 'organized': 3, 'comprehensibl...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   record_id                                         raw_output  accurate  \\\n",
       "0          0  {\"accurate\": 2, \"organized\": 5, \"comprehensibl...         2   \n",
       "1          1  {'accurate': 2, 'organized': 5, 'comprehensibl...         2   \n",
       "2          2  {\"accurate\": 5, \"organized\": 2, \"comprehensibl...         5   \n",
       "3          3  {'accurate': 4, 'organized': 5, 'comprehensibl...         4   \n",
       "4          4  {'accurate': 2, 'organized': 3, 'comprehensibl...         2   \n",
       "\n",
       "   organized  comprehensible  succinct  parse_ok  \n",
       "0          5               5         5      True  \n",
       "1          5               5         5      True  \n",
       "2          2               5         2      True  \n",
       "3          5               4         2      True  \n",
       "4          3               3         1      True  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onco_raw = pd.read_csv(os.path.join(onco_output_path, \"deepseek_raw_outputs_onco_realworld_test.csv\"))\n",
    "basic_raw = pd.read_csv(os.path.join(basic_output_path, \"deepseek_raw_outputs_basic_realworld_test.csv\"))\n",
    "reviewer_raw = pd.read_csv(os.path.join(reviewer_output_path, \"deepseek_raw_outputs_reviewer_realworld_test.csv\"))\n",
    "\n",
    "basic_raw = clean_rawdf(basic_raw)\n",
    "onco_raw = clean_rawdf(onco_raw)\n",
    "reviewer_raw = clean_rawdf(reviewer_raw)\n",
    "\n",
    "basic_raw.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9cd1dbe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accurate</th>\n",
       "      <th>organized</th>\n",
       "      <th>comprehensible</th>\n",
       "      <th>succinct</th>\n",
       "      <th>record_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  accurate organized comprehensible succinct  record_id\n",
       "0        2         5              5        5          0\n",
       "1        2         5              5        5          1\n",
       "2        5         2              5        2          2\n",
       "3        4         5              4        2          3\n",
       "4        2         3              3        1          4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def expand_rawdf(raw_df):\n",
    "    raw_df_expanded = raw_df['raw_output'].str.split(',', expand=True)\n",
    "    raw_df_expanded.head()\n",
    "\n",
    "    # remove all non-numeric characters from each cell in raw_df_expanded and rename columns to accurate, organized, comprehensible, succinct\n",
    "    for i, col in enumerate(raw_df_expanded.columns):\n",
    "        raw_df_expanded[col] = raw_df_expanded[col].str.replace(r'[^0-9.]', '', regex=True)\n",
    "        if i == 0:\n",
    "            raw_df_expanded.rename(columns={col: 'accurate'}, inplace=True)\n",
    "        elif i == 1:\n",
    "            raw_df_expanded.rename(columns={col: 'organized'}, inplace=True)\n",
    "        elif i == 2:\n",
    "            raw_df_expanded.rename(columns={col: 'comprehensible'}, inplace=True)\n",
    "        elif i == 3:\n",
    "            raw_df_expanded.rename(columns={col: 'succinct'}, inplace=True)\n",
    "\n",
    "    # add record_id column back to raw_df_expanded\n",
    "    raw_df_expanded['record_id'] = raw_df['record_id']\n",
    "    return raw_df_expanded\n",
    "\n",
    "basic_raw_expanded = expand_rawdf(basic_raw)\n",
    "onco_raw_expanded = expand_rawdf(onco_raw)\n",
    "reviewer_raw_expanded = expand_rawdf(reviewer_raw)\n",
    "basic_raw_expanded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17538149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_scorefile(raw_df, scoreFile):\n",
    "    for i, row in scoreFile.iterrows():\n",
    "        record_id = row['record_id']\n",
    "        matching_row = raw_df[raw_df['record_id'] == record_id]\n",
    "        if not matching_row.empty:\n",
    "            scoreFile.at[i, 'accurate'] = matching_row['accurate'].values[0]\n",
    "            scoreFile.at[i, 'organized'] = matching_row['organized'].values[0]\n",
    "            scoreFile.at[i, 'comprehensible'] = matching_row['comprehensible'].values[0]\n",
    "            scoreFile.at[i, 'succinct'] = matching_row['succinct'].values[0]\n",
    "    return scoreFile\n",
    "\n",
    "basic_scorefile = replace_scorefile(basic_raw_expanded, basic_scorefile)\n",
    "onco_scorefile = replace_scorefile(onco_raw_expanded, onco_scorefile)\n",
    "reviewer_scorefile = replace_scorefile(reviewer_raw_expanded, reviewer_scorefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "637f596e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Summary</th>\n",
       "      <th>accurate</th>\n",
       "      <th>organized</th>\n",
       "      <th>comprehensible</th>\n",
       "      <th>succinct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Metformin</td>\n",
       "      <td>)&lt;Output&gt;\\n{{\\n  \"Mechanism\": \"&lt;Metformin targ...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Pioglitazone</td>\n",
       "      <td>)&lt;Output format&gt;\\n{{\\n  \"Mechanism\": \"&lt;Pioglit...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Alogliptin</td>\n",
       "      <td>)&lt;Output format&gt;\\n{{\\n  \"Mechanism\": \"&lt;Aloglip...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Linagliptin</td>\n",
       "      <td>)&lt;Output format&gt;\\n{{\\n  \"Mechanism\": \"&lt;Linagli...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Sitagliptin</td>\n",
       "      <td>)&lt;Output format&gt;\\n{{\\n  \"Mechanism\": \"&lt;Sitagli...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   record_id          Drug                                            Summary  \\\n",
       "0          0     Metformin  )<Output>\\n{{\\n  \"Mechanism\": \"<Metformin targ...   \n",
       "1          1  Pioglitazone  )<Output format>\\n{{\\n  \"Mechanism\": \"<Pioglit...   \n",
       "2          2    Alogliptin  )<Output format>\\n{{\\n  \"Mechanism\": \"<Aloglip...   \n",
       "3          3   Linagliptin  )<Output format>\\n{{\\n  \"Mechanism\": \"<Linagli...   \n",
       "4          4   Sitagliptin  )<Output format>\\n{{\\n  \"Mechanism\": \"<Sitagli...   \n",
       "\n",
       "  accurate organized comprehensible succinct  \n",
       "0        2         5              5        5  \n",
       "1        2         5              5        5  \n",
       "2        5         2              5        2  \n",
       "3        4         5              4        2  \n",
       "4        2         3              3        1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_scorefile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b3e62c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleaned scorefiles\n",
    "basic_scorefile.to_csv(os.path.join(basic_output_path, \"deepseek_cleaned_ratings_basic_realworld_test.csv\"), index=False)\n",
    "onco_scorefile.to_csv(os.path.join(onco_output_path, \"deepseek_cleaned_ratings_onco_realworld_test.csv\"), index=False)\n",
    "reviewer_scorefile.to_csv(os.path.join(reviewer_output_path, \"deepseek_cleaned_ratings_reviewer_realworld_test.csv\"), index=False)\n",
    "\n",
    "# save raw outputs\n",
    "basic_raw_expanded.to_csv(os.path.join(basic_output_path, \"deepseek_raw_outputs_cleaned_basic_realworld_test.csv\"), index=False)\n",
    "onco_raw_expanded.to_csv(os.path.join(onco_output_path, \"deepseek_raw_outputs_cleaned_onco_realworld_test.csv\"), index=False)\n",
    "reviewer_raw_expanded.to_csv(os.path.join(reviewer_output_path, \"deepseek_raw_outputs_cleaned_reviewer_realworld_test.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25751d61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
