{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8abba360",
   "metadata": {},
   "source": [
    "# TTD Data Extraction\n",
    "\n",
    "The purpose of this jupyter notebook is to create a csv from the TTD Dataset P1-01 from [TTD Website](https://ttd.idrblab.cn/full-data-download).\n",
    "\n",
    "This P1-01 file comes in a txt format with details of the data source.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e63d760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import os\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e431e1e",
   "metadata": {},
   "source": [
    "## Preview the txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf584b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ttd(file_path, lines=50):\n",
    "    \"\"\"\n",
    "    Read and preview the first few lines of a TTD .txt file to inspect its format.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the file.\n",
    "        lines (int): Number of lines to preview.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = file.readlines()\n",
    "    \n",
    "    print(f\"--- Previewing: {file_path} ({min(lines, len(data))} of {len(data)} lines) ---\\n\")\n",
    "    for line in data[:lines]:\n",
    "        print(line.rstrip())\n",
    "\n",
    "\n",
    "\n",
    "read_ttd(\"path/to/dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987838e5",
   "metadata": {},
   "source": [
    "## Extract table from the txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cd1439",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# File paths (update as needed)\n",
    "file_target = \"C:\\\\Users\\\\alici\\\\OneDrive - Nanyang Technological University\\\\FYP\\\\fyp-database\\\\Databases\\\\TTD\\\\P1-01-TTD_target_download.txt\"\n",
    "\n",
    "\n",
    "def parse_p1_01(file_path):\n",
    "    \"\"\"Parses P1-01-TTD_target_download.txt into structured rows.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    targets = []\n",
    "    current = {}\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line or line.startswith('---') or line.startswith('TTD -'):\n",
    "            continue\n",
    "        if '\\t' in line:\n",
    "            parts = line.split('\\t')\n",
    "            if len(parts) >= 3:\n",
    "                target_id, key, value = parts[0], parts[1], '\\t'.join(parts[2:])\n",
    "                if key == 'TARGETID' and current:\n",
    "                    targets.append(current)\n",
    "                    current = {}\n",
    "                if key.startswith('DRUGINFO'):\n",
    "                    if 'DRUGINFO' not in current:\n",
    "                        current['DRUGINFO'] = []\n",
    "                    current['DRUGINFO'].append(value)\n",
    "                else:\n",
    "                    current[key] = value\n",
    "    if current:\n",
    "        targets.append(current)\n",
    "\n",
    "    # Expand DRUGINFO entries\n",
    "    expanded_rows = []\n",
    "    for entry in targets:\n",
    "        base = entry.copy()\n",
    "        drug_infos = base.pop('DRUGINFO', [])\n",
    "        for drug_info in drug_infos:\n",
    "            dparts = drug_info.split('\\t')\n",
    "            if len(dparts) >= 3:\n",
    "                base_copy = base.copy()\n",
    "                base_copy['TTDDRUID'] = dparts[0]\n",
    "                base_copy['DRUGNAME'] = dparts[1]\n",
    "                base_copy['CLINICAL_STATUS'] = dparts[2]\n",
    "                expanded_rows.append(base_copy)\n",
    "            else:\n",
    "                expanded_rows.append(base)\n",
    "    return pd.DataFrame(expanded_rows)\n",
    "\n",
    "df_target = parse_p1_01(file_target)\n",
    "df_target.to_csv('path/to/save/csv', index=True)\n",
    "df_target.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34955de1",
   "metadata": {},
   "source": [
    "## Filter by clinical status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2afb20d",
   "metadata": {},
   "source": [
    "### Read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e8013c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read parsed_target data\n",
    "drug_target = pd.read_csv('path/to/save/csv')\n",
    "drug_target.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34e25ae",
   "metadata": {},
   "source": [
    "### Filter by relevant clinical status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260bbe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_statuses = ['Approved', 'Approved in China', 'Approved in EU', 'Approved (orphan drug)']\n",
    "drug_target_filtered = drug_target[drug_target['CLINICAL_STATUS'].isin(clinical_statuses)]\n",
    "print(np.shape(drug_target_filtered))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea930559",
   "metadata": {},
   "source": [
    "### Keep only necessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f22028",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_target_final = drug_target_filtered[['DRUGNAME', 'TARGNAME']].drop_duplicates().reset_index(drop=True)\n",
    "print(np.shape(drug_target_final))\n",
    "\n",
    "# save to csv\n",
    "drug_target_final.to_csv('path/to/drugtargetfinal', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
