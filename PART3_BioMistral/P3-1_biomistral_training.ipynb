{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6f42387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Standard Library\n",
    "# ================================\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "# ================================\n",
    "# Third-Party Libraries\n",
    "# ================================\n",
    "import bitsandbytes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "# HuggingFace Transformers\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    EarlyStoppingCallback,\n",
    "    GenerationConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    __version__ as HF_VER,\n",
    ")\n",
    "\n",
    "# PEFT (LoRA / QLoRA)\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftModel,\n",
    "    TaskType,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    ")\n",
    "\n",
    "# TRL (Supervised Fine-Tuning Trainer)\n",
    "from trl import SFTConfig, SFTTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5e8ffe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(yaml_path):\n",
    "    with open(yaml_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "    \n",
    "file_paths = load_config(yaml_path=\"P3-config.yaml\")\n",
    "PARAMS = load_config(yaml_path=\"training_params.yaml\")\n",
    "prompts = load_config(yaml_path=\"prompts.yaml\")\n",
    "\n",
    "dtype = \"bf16\" if torch.cuda.is_bf16_supported() else \"fp16\"\n",
    "PARAMS[\"model\"][\"dtype\"] = dtype\n",
    "PARAMS[\"bnb\"][\"compute_dtype\"] = dtype\n",
    "PARAMS[\"train\"][\"bf16\"] = torch.cuda.is_bf16_supported()\n",
    "PARAMS[\"train\"][\"fp16\"] = not torch.cuda.is_bf16_supported()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "77a5ee3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drug</th>\n",
       "      <th>Receptor</th>\n",
       "      <th>PDB_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Metformin</td>\n",
       "      <td>Acetyl-CoA carboxylase 2</td>\n",
       "      <td>3FF6,3TDC,2X24,3JRX,3JRW,2HJW,4HQ6,5KKN,3GLK,3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cetuximab</td>\n",
       "      <td>Epidermal growth factor receptor</td>\n",
       "      <td>7SZ7,7SZ5,7SYE,7SYD,7SZ1,7SZ0,8HGS,8HGP,8HGO,5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bevacizumab</td>\n",
       "      <td>Vascular endothelial growth factor A</td>\n",
       "      <td>3V2A,5T89,8UWZ,6T9D,7KF1,7KF0,7KEZ,5FV2,5FV1,3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pioglitazone</td>\n",
       "      <td>Peroxisome proliferator-activated receptor gamma</td>\n",
       "      <td>3E00,3DZY,3DZU,7QB1,6L89,6K0T,6AD9,5HZC,5F9B,5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adenosine triphosphate</td>\n",
       "      <td>Tyrosine-protein kinase ABL1</td>\n",
       "      <td>5MO4,1OPK,1OPL,2FO0,8SSN,4XEY,6XR7,6XR6,2E2B,4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Drug                                          Receptor  \\\n",
       "0               Metformin                          Acetyl-CoA carboxylase 2   \n",
       "1               Cetuximab                  Epidermal growth factor receptor   \n",
       "2             Bevacizumab              Vascular endothelial growth factor A   \n",
       "3            Pioglitazone  Peroxisome proliferator-activated receptor gamma   \n",
       "4  Adenosine triphosphate                      Tyrosine-protein kinase ABL1   \n",
       "\n",
       "                                              PDB_ID  \n",
       "0  3FF6,3TDC,2X24,3JRX,3JRW,2HJW,4HQ6,5KKN,3GLK,3...  \n",
       "1  7SZ7,7SZ5,7SYE,7SYD,7SZ1,7SZ0,8HGS,8HGP,8HGO,5...  \n",
       "2  3V2A,5T89,8UWZ,6T9D,7KF1,7KF0,7KEZ,5FV2,5FV1,3...  \n",
       "3  3E00,3DZY,3DZU,7QB1,6L89,6K0T,6AD9,5HZC,5F9B,5...  \n",
       "4  5MO4,1OPK,1OPL,2FO0,8SSN,4XEY,6XR7,6XR6,2E2B,4...  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "drug_data_path = file_paths[\"input_file_paths\"][\"drug_data_path\"]\n",
    "\n",
    "drug_data_df = pd.read_csv(drug_data_path)\n",
    "drug_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4878cfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summaries_path = file_paths[\"input_file_paths\"][\"summaries_path\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49929ab",
   "metadata": {},
   "source": [
    "### data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c0ffb6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drug</th>\n",
       "      <th>Receptor</th>\n",
       "      <th>PDB_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Metformin</td>\n",
       "      <td>Acetyl-CoA carboxylase 2</td>\n",
       "      <td>3FF6,3TDC,2X24,3JRX,3JRW,2HJW,4HQ6,5KKN,3GLK,3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cetuximab</td>\n",
       "      <td>Epidermal growth factor receptor</td>\n",
       "      <td>7SZ7,7SZ5,7SYE,7SYD,7SZ1,7SZ0,8HGS,8HGP,8HGO,5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bevacizumab</td>\n",
       "      <td>Vascular endothelial growth factor A</td>\n",
       "      <td>3V2A,5T89,8UWZ,6T9D,7KF1,7KF0,7KEZ,5FV2,5FV1,3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pioglitazone</td>\n",
       "      <td>Peroxisome proliferator-activated receptor gamma</td>\n",
       "      <td>3E00,3DZY,3DZU,7QB1,6L89,6K0T,6AD9,5HZC,5F9B,5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adenosine triphosphate</td>\n",
       "      <td>Tyrosine-protein kinase ABL1</td>\n",
       "      <td>5MO4,1OPK,1OPL,2FO0,8SSN,4XEY,6XR7,6XR6,2E2B,4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Drug                                          Receptor  \\\n",
       "0               Metformin                          Acetyl-CoA carboxylase 2   \n",
       "1               Cetuximab                  Epidermal growth factor receptor   \n",
       "2             Bevacizumab              Vascular endothelial growth factor A   \n",
       "3            Pioglitazone  Peroxisome proliferator-activated receptor gamma   \n",
       "4  Adenosine triphosphate                      Tyrosine-protein kinase ABL1   \n",
       "\n",
       "                                              PDB_ID  \n",
       "0  3FF6,3TDC,2X24,3JRX,3JRW,2HJW,4HQ6,5KKN,3GLK,3...  \n",
       "1  7SZ7,7SZ5,7SYE,7SYD,7SZ1,7SZ0,8HGS,8HGP,8HGO,5...  \n",
       "2  3V2A,5T89,8UWZ,6T9D,7KF1,7KF0,7KEZ,5FV2,5FV1,3...  \n",
       "3  3E00,3DZY,3DZU,7QB1,6L89,6K0T,6AD9,5HZC,5F9B,5...  \n",
       "4  5MO4,1OPK,1OPL,2FO0,8SSN,4XEY,6XR7,6XR6,2E2B,4...  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_data_clean = drug_data_df.copy()\n",
    "drug_data_clean.columns\n",
    "\n",
    "drug_data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7099e7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _norm(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", str(s).strip().upper())\n",
    "\n",
    "def _safe(s: Optional[str]) -> str:\n",
    "    return \"\" if s is None else str(s).strip()\n",
    "\n",
    "def _read_text_file(path: str) -> Optional[str]:\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            txt = f.read().strip()\n",
    "            return txt if txt else None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _canon(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Lowercase; turn any run of non-alphanumerics (incl. underscores, hyphens, commas)\n",
    "    into a single space; then collapse spaces.\n",
    "    \"\"\"\n",
    "    s = str(s).lower().strip()\n",
    "    s = re.sub(r\"[^a-z0-9]+\", \" \", s)   # underscores, hyphens, slashes -> space\n",
    "    return re.sub(r\"\\s+\", \" \", s).strip()\n",
    "\n",
    "\n",
    "def load_reports_dir(reports_dir: str) -> Dict[str, str]:\n",
    "    pat_file = re.compile(r\"^(.+?)_summary\\.txt$\", re.I)\n",
    "    pat_rm   = re.compile(r\"PMID:\\s*\\d+\\s*(?:\\n\\s*)?(?:no relevant information found\\.?)\",\n",
    "                          re.I)\n",
    "\n",
    "    out = {}\n",
    "\n",
    "    for p in glob.glob(os.path.join(reports_dir, \"*_summary.txt\")):\n",
    "        fn = os.path.basename(p)\n",
    "        m = pat_file.match(fn)\n",
    "        if not m:\n",
    "            continue\n",
    "\n",
    "        key = _canon(m.group(1))\n",
    "\n",
    "\n",
    "        txt = _read_text_file(p)\n",
    "        if not txt:\n",
    "            continue\n",
    "\n",
    "        # remove junk pmid blocks\n",
    "        txt = pat_rm.sub(\"\", txt)\n",
    "\n",
    "        # collapse lines\n",
    "        txt = re.sub(r\"\\n{3,}\", \"\\n\\n\", txt).strip()\n",
    "\n",
    "        # *** reject empty after cleaning ***\n",
    "        if not txt:\n",
    "            # optional debug: print(f\"SKIP blank: {fn}\")\n",
    "            continue\n",
    "\n",
    "        out[key] = txt\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d5b70905-8d36-444c-b514-ff6dc37dd74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 | amphetamine\n",
      "PMID: 39287256\n",
      "The study found KEGG enrichment of shared NASH/type 2 diabetes targets in the \"amphetamine\n",
      "addiction\" pathway alongside colorectal cancer, PPAR signaling and toll‑like receptor signalin ...\n",
      "\n",
      "01 | semaglutide\n",
      "PMID: 40437949\n",
      "Semaglutide, as a GLP‑1 receptor agonist used to treat diabetes and obesity, was part of trials\n",
      "pooled here showing no overall cancer risk but a small increased colorectal cancer signal ...\n",
      "\n",
      "02 | adenosine monophosphate\n",
      "PMID: 37071615\n",
      "Patchouli alcohol (PA) treatment increased phosphorylation (activation) of 5' adenosine\n",
      "monophosphate‑activated protein kinase (AMPK) alongside protein kinase B (Akt) in differentiated\n",
      " ...\n",
      "\n",
      "03 | hydroxychloroquine\n",
      "PMID: 33608672\n",
      "The study shows that blocking autophagy with chloroquine potentiated killing of KRAS‑mutant CRC\n",
      "cells treated with glycolysis and OXPHOS inhibitors; by extension, hydroxychloroquine (a  ...\n",
      "\n",
      "04 | cimetidine\n",
      "PMID: 12938277\n",
      "In this case report of a diabetic patient with ascending colon carcinoma and lung metastases,\n",
      "postoperative oral cimetidine (800 mg/day) given with 5'-DFUR was associated with relativel ...\n",
      "\n",
      "05 | thiazolidinedione\n",
      "PMID: 31887708\n",
      "In this large population-based cohort of patients with newly diagnosed type 2 diabetes, use of\n",
      "thiazolidinediones was not associated with a change in colorectal cancer risk. The study t ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reports_dict = load_reports_dir(summaries_path)\n",
    "\n",
    "for i, (drug, text) in enumerate(reports_dict.items()):\n",
    "    print(f\"{i:02d} | {drug}\")\n",
    "    print(text[:200], \"...\\n\")      # first 200 chars preview\n",
    "\n",
    "    if i> 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec9e006",
   "metadata": {},
   "source": [
    "### merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "68f13e04-8236-489f-8fdc-b5827e3cab79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- DRUG → report_key → exists ----\n",
      "Metformin                           → metformin                           → True\n",
      "Cetuximab                           → cetuximab                           → True\n",
      "Bevacizumab                         → bevacizumab                         → True\n",
      "Pioglitazone                        → pioglitazone                        → True\n",
      "Adenosine triphosphate              → adenosine triphosphate              → True\n",
      "Thiazolidinedione                   → thiazolidinedione                   → True\n",
      "Estrogen                            → estrogen                            → True\n",
      "Exenatide                           → exenatide                           → True\n",
      "Adenosine monophosphate             → adenosine monophosphate             → True\n",
      "Dapagliflozin                       → dapagliflozin                       → True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## map drug report name to actual drug name from dataset\n",
    "drug_data_clean[\"report_key\"] = drug_data_clean[\"Drug\"].map(_canon)\n",
    "drug_data_clean[\"report\"] = drug_data_clean[\"report_key\"].map(lambda k: reports_dict.get(k))\n",
    "print(\"---- DRUG → report_key → exists ----\")\n",
    "for d, k in drug_data_clean[[\"Drug\",\"report_key\"]].head(10).values:\n",
    "    print(f\"{d:<35} → {k:<35} → {k in reports_dict}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2fbad74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drug</th>\n",
       "      <th>Receptor</th>\n",
       "      <th>PDB_ID</th>\n",
       "      <th>report_key</th>\n",
       "      <th>report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Metformin</td>\n",
       "      <td>Acetyl-CoA carboxylase 2</td>\n",
       "      <td>3FF6,3TDC,2X24,3JRX,3JRW,2HJW,4HQ6,5KKN,3GLK,3...</td>\n",
       "      <td>metformin</td>\n",
       "      <td>In this retrospective study of locally advance...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cetuximab</td>\n",
       "      <td>Epidermal growth factor receptor</td>\n",
       "      <td>7SZ7,7SZ5,7SYE,7SYD,7SZ1,7SZ0,8HGS,8HGP,8HGO,5...</td>\n",
       "      <td>cetuximab</td>\n",
       "      <td>This case report links cetuximab (used as biol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bevacizumab</td>\n",
       "      <td>Vascular endothelial growth factor A</td>\n",
       "      <td>3V2A,5T89,8UWZ,6T9D,7KF1,7KF0,7KEZ,5FV2,5FV1,3...</td>\n",
       "      <td>bevacizumab</td>\n",
       "      <td>Bevacizumab was used in this metastatic CRC ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pioglitazone</td>\n",
       "      <td>Peroxisome proliferator-activated receptor gamma</td>\n",
       "      <td>3E00,3DZY,3DZU,7QB1,6L89,6K0T,6AD9,5HZC,5F9B,5...</td>\n",
       "      <td>pioglitazone</td>\n",
       "      <td>Pioglitazone, a PPARG (thiazolidinedione) agon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adenosine triphosphate</td>\n",
       "      <td>Tyrosine-protein kinase ABL1</td>\n",
       "      <td>5MO4,1OPK,1OPL,2FO0,8SSN,4XEY,6XR7,6XR6,2E2B,4...</td>\n",
       "      <td>adenosine triphosphate</td>\n",
       "      <td>The abstract notes tumor (including colorectal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Valproate</td>\n",
       "      <td>Glycogen synthase kinase-3 alpha</td>\n",
       "      <td>7SXF,7SXG,8VMG,8VMF,8VME,4NM7,4NM5,5K5N,6TCU,3...</td>\n",
       "      <td>valproate</td>\n",
       "      <td>The HDAC inhibitor sodium valproate reduced di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Venlafaxine</td>\n",
       "      <td>Serotonin transporter</td>\n",
       "      <td>6VRL,6VRK,6VRH,7TXT,7LWD,5I6Z,6W2C,6W2B,6DZZ,6...</td>\n",
       "      <td>venlafaxine</td>\n",
       "      <td>The abstract reports that venlafaxine provides...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Vildagliptin</td>\n",
       "      <td>Dipeptidyl peptidase 4</td>\n",
       "      <td>2QTB,2QT9,2BGR,2JID,3F8S,2QJR,3W2T,3VJM,3VJL,3...</td>\n",
       "      <td>vildagliptin</td>\n",
       "      <td>Vildagliptin, as a member of the DPP‑4 inhibit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Vitamin B6</td>\n",
       "      <td>Aromatic-L-amino-acid decarboxylase</td>\n",
       "      <td>9GNS,8ORA,8OR9,3RCH,3RBL,3RBF,9HRH,9HRI,1JS6,1JS3</td>\n",
       "      <td>vitamin b6</td>\n",
       "      <td>In this cohort of stage III colon cancer patie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Zanubrutinib</td>\n",
       "      <td>Tyrosine-protein kinase BTK</td>\n",
       "      <td>8GMB,4XI2,8FLG,6W07,6W06,6VXQ,6NZM,6HRT,6HRP,6...</td>\n",
       "      <td>zanubrutinib</td>\n",
       "      <td>The abstract lists zanubrutinib as one of seve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Drug                                          Receptor  \\\n",
       "0                Metformin                          Acetyl-CoA carboxylase 2   \n",
       "1                Cetuximab                  Epidermal growth factor receptor   \n",
       "2              Bevacizumab              Vascular endothelial growth factor A   \n",
       "3             Pioglitazone  Peroxisome proliferator-activated receptor gamma   \n",
       "4   Adenosine triphosphate                      Tyrosine-protein kinase ABL1   \n",
       "..                     ...                                               ...   \n",
       "63               Valproate                  Glycogen synthase kinase-3 alpha   \n",
       "64             Venlafaxine                             Serotonin transporter   \n",
       "65            Vildagliptin                            Dipeptidyl peptidase 4   \n",
       "66              Vitamin B6               Aromatic-L-amino-acid decarboxylase   \n",
       "67            Zanubrutinib                       Tyrosine-protein kinase BTK   \n",
       "\n",
       "                                               PDB_ID              report_key  \\\n",
       "0   3FF6,3TDC,2X24,3JRX,3JRW,2HJW,4HQ6,5KKN,3GLK,3...               metformin   \n",
       "1   7SZ7,7SZ5,7SYE,7SYD,7SZ1,7SZ0,8HGS,8HGP,8HGO,5...               cetuximab   \n",
       "2   3V2A,5T89,8UWZ,6T9D,7KF1,7KF0,7KEZ,5FV2,5FV1,3...             bevacizumab   \n",
       "3   3E00,3DZY,3DZU,7QB1,6L89,6K0T,6AD9,5HZC,5F9B,5...            pioglitazone   \n",
       "4   5MO4,1OPK,1OPL,2FO0,8SSN,4XEY,6XR7,6XR6,2E2B,4...  adenosine triphosphate   \n",
       "..                                                ...                     ...   \n",
       "63  7SXF,7SXG,8VMG,8VMF,8VME,4NM7,4NM5,5K5N,6TCU,3...               valproate   \n",
       "64  6VRL,6VRK,6VRH,7TXT,7LWD,5I6Z,6W2C,6W2B,6DZZ,6...             venlafaxine   \n",
       "65  2QTB,2QT9,2BGR,2JID,3F8S,2QJR,3W2T,3VJM,3VJL,3...            vildagliptin   \n",
       "66  9GNS,8ORA,8OR9,3RCH,3RBL,3RBF,9HRH,9HRI,1JS6,1JS3              vitamin b6   \n",
       "67  8GMB,4XI2,8FLG,6W07,6W06,6VXQ,6NZM,6HRT,6HRP,6...            zanubrutinib   \n",
       "\n",
       "                                               report  \n",
       "0   In this retrospective study of locally advance...  \n",
       "1   This case report links cetuximab (used as biol...  \n",
       "2   Bevacizumab was used in this metastatic CRC ca...  \n",
       "3   Pioglitazone, a PPARG (thiazolidinedione) agon...  \n",
       "4   The abstract notes tumor (including colorectal...  \n",
       "..                                                ...  \n",
       "63  The HDAC inhibitor sodium valproate reduced di...  \n",
       "64  The abstract reports that venlafaxine provides...  \n",
       "65  Vildagliptin, as a member of the DPP‑4 inhibit...  \n",
       "66  In this cohort of stage III colon cancer patie...  \n",
       "67  The abstract lists zanubrutinib as one of seve...  \n",
       "\n",
       "[68 rows x 5 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "reports_dict = load_reports_dir(summaries_path)\n",
    "\n",
    "drug_data_clean[\"report\"] = drug_data_clean[\"report_key\"].map(reports_dict.get)\n",
    "\n",
    "\n",
    "drug_data_clean[\"report\"] = drug_data_clean[\"report\"].apply(\n",
    "    lambda txt: pat_drop_pmid.sub(\"\", txt).strip() if isinstance(txt, str) else txt\n",
    ")\n",
    "drug_data_clean = drug_data_clean.dropna(subset=[\"report\"]).reset_index(drop=True)\n",
    "print(drug_data_clean.shape)\n",
    "\n",
    "drug_data_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dc2163",
   "metadata": {},
   "source": [
    "### split into train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "60f2490e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68, 5)\n",
      "54 14\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(drug_data_clean.shape)\n",
    "train_df, val_df = train_test_split(\n",
    "    drug_data_clean,\n",
    "    test_size=0.2,          # 20% test\n",
    "    random_state=42,        # reproducible\n",
    "    shuffle=True\n",
    ")\n",
    "train_df_path = file_paths[\"train_val_paths\"][\"train_path\"]\n",
    "val_df_path = file_paths[\"train_val_paths\"][\"val_path\"]\n",
    "\n",
    "train_df.to_csv(train_df_path)\n",
    "val_df.to_csv(val_df_path)\n",
    "\n",
    "print(len(train_df), len(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "132a0cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drug</th>\n",
       "      <th>Receptor</th>\n",
       "      <th>PDB_ID</th>\n",
       "      <th>report_key</th>\n",
       "      <th>report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Prasugrel</td>\n",
       "      <td>P2Y purinoceptor 12</td>\n",
       "      <td>7XXI,7PP1,4PY0,4PXZ,4NTJ</td>\n",
       "      <td>prasugrel</td>\n",
       "      <td>In TRITON, prasugrel was associated with an ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Progesterone</td>\n",
       "      <td>Progesterone receptor</td>\n",
       "      <td>1SQN,3G8O,4APU,4A2J,3ZRB,3ZRA,3ZR7,2W8Y,3HQ5,3...</td>\n",
       "      <td>progesterone</td>\n",
       "      <td>The study links hyperglycemia to increased orn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Maraviroc</td>\n",
       "      <td>C-C chemokine receptor type 5</td>\n",
       "      <td>7O7F,4MBS,7F1S,7F1Q,7F1R,6MET,6MEO</td>\n",
       "      <td>maraviroc</td>\n",
       "      <td>Maraviroc, a CCR5 inhibitor, was tested with p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Exenatide</td>\n",
       "      <td>Glucagon-like peptide 1 receptor</td>\n",
       "      <td>7FIM,7RTB,9J1P,9IVM,9IVG,9EBQ,9EBO,9EBN,9C0K,9...</td>\n",
       "      <td>exenatide</td>\n",
       "      <td>Exenatide, as a GLP‑1 receptor agonist used to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Hydroxychloroquine</td>\n",
       "      <td>Toll-like receptor 7</td>\n",
       "      <td>7CYN,9MHV,8TTZ,8TTY,8S9H,5GMH,5GMG,5GMF,7YTP,8...</td>\n",
       "      <td>hydroxychloroquine</td>\n",
       "      <td>The study shows that blocking autophagy with c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Drug                          Receptor  \\\n",
       "54           Prasugrel               P2Y purinoceptor 12   \n",
       "55        Progesterone             Progesterone receptor   \n",
       "49           Maraviroc     C-C chemokine receptor type 5   \n",
       "7            Exenatide  Glucagon-like peptide 1 receptor   \n",
       "42  Hydroxychloroquine              Toll-like receptor 7   \n",
       "\n",
       "                                               PDB_ID          report_key  \\\n",
       "54                           7XXI,7PP1,4PY0,4PXZ,4NTJ           prasugrel   \n",
       "55  1SQN,3G8O,4APU,4A2J,3ZRB,3ZRA,3ZR7,2W8Y,3HQ5,3...        progesterone   \n",
       "49                 7O7F,4MBS,7F1S,7F1Q,7F1R,6MET,6MEO           maraviroc   \n",
       "7   7FIM,7RTB,9J1P,9IVM,9IVG,9EBQ,9EBO,9EBN,9C0K,9...           exenatide   \n",
       "42  7CYN,9MHV,8TTZ,8TTY,8S9H,5GMH,5GMG,5GMF,7YTP,8...  hydroxychloroquine   \n",
       "\n",
       "                                               report  \n",
       "54  In TRITON, prasugrel was associated with an ex...  \n",
       "55  The study links hyperglycemia to increased orn...  \n",
       "49  Maraviroc, a CCR5 inhibitor, was tested with p...  \n",
       "7   Exenatide, as a GLP‑1 receptor agonist used to...  \n",
       "42  The study shows that blocking autophagy with c...  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9b9dba",
   "metadata": {},
   "source": [
    "## llm training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f782d424",
   "metadata": {},
   "source": [
    "### load model configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1cb8ef00",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID   = PARAMS[\"model\"][\"id\"]\n",
    "MODEL_OUTPUT_DIR = PARAMS[\"model\"][\"output_dir\"] ## save model configs here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5dd19b",
   "metadata": {},
   "source": [
    "### training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da628675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _dtype_from_str(s: str):\n",
    "    s = (s or \"\").lower()\n",
    "    if s in (\"bf16\", \"bfloat16\"):\n",
    "        return torch.bfloat16\n",
    "    if s in (\"fp16\", \"float16\", \"half\"):\n",
    "        return torch.float16\n",
    "    if s in (\"fp32\", \"float32\"):\n",
    "        return torch.float32\n",
    "    if s in (\"auto\", \"\"):\n",
    "        return None\n",
    "    raise ValueError(f\"Unknown dtype string: {s!r}\")\n",
    "\n",
    "\n",
    "def _normalize_max_memory(mm: Optional[Dict[Any, str]]) -> Optional[Dict[Any, str]]:\n",
    "    \"\"\"\n",
    "    - Convert string keys like \"0\" to int 0.\n",
    "    - Drop GPU entries if there is no CUDA device.\n",
    "    - Leave 'cpu' / 'mps' / 'disk' untouched.\n",
    "    \"\"\"\n",
    "    if not mm:\n",
    "        return None\n",
    "\n",
    "    has_cuda = torch.cuda.is_available() and torch.cuda.device_count() > 0\n",
    "    out: Dict[Any, str] = {}\n",
    "\n",
    "    for k, v in mm.items():\n",
    "        # \"0\" -> 0\n",
    "        if isinstance(k, str) and k.isdigit():\n",
    "            k_int = int(k)\n",
    "            if has_cuda and k_int < torch.cuda.device_count():\n",
    "                out[k_int] = v\n",
    "            # if no CUDA or out-of-range GPU id, just skip\n",
    "        else:\n",
    "            out[k] = v\n",
    "\n",
    "    return out or None\n",
    "\n",
    "\n",
    "def load_dataframe(path: str):\n",
    "    df = pd.read_csv(path)\n",
    "    drop_cols = PARAMS[\"data\"][\"dropna_cols\"]\n",
    "    df = df.dropna(subset=drop_cols).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "class SafeDict(dict):\n",
    "    def __missing__(self, key):\n",
    "        return \"\"  # default blank for any missing placeholder\n",
    "\n",
    "def get_first_key(ex, keys):\n",
    "    \"\"\"Return first non-empty value among candidate keys from a row/example.\"\"\"\n",
    "    for k in keys:\n",
    "        if k in ex and ex[k] is not None and str(ex[k]).strip() != \"\":\n",
    "            return str(ex[k])\n",
    "    return \"\"\n",
    "\n",
    "def chat_format_map_fn(\n",
    "    ex: Dict[str, Any],\n",
    "    training_prompt: str,\n",
    "    system_prompt: str,\n",
    "    few_shots: List[Dict[str, str]],\n",
    "    tokenizer: AutoTokenizer,\n",
    ") -> Dict[str, str]:\n",
    "    \"\"\"Map a row into chat-formatted text for SFT.\"\"\"\n",
    "    vals = {\n",
    "        \"Drug\": ex.get(\"Drug\", \"\"),\n",
    "        \"Receptor\": ex.get(\"Receptor\", \"\"),\n",
    "        \"report\": ex.get(\"report\", \"\"),\n",
    "        \"PDB_ID\": ex.get(\"PDB_ID\", \"\"),\n",
    "    }\n",
    "    user_text = training_prompt.format_map(SafeDict(vals))\n",
    "\n",
    "    # few-shots (if any)\n",
    "    msgs: List[Dict[str, str]] = []\n",
    "    for shot in few_shots or []:\n",
    "        if shot and \"user\" in shot and \"assistant\" in shot:\n",
    "            msgs.append({\"role\": \"user\", \"content\": shot[\"user\"]})\n",
    "            msgs.append({\"role\": \"assistant\", \"content\": shot[\"assistant\"]})\n",
    "\n",
    "    # fold system into first user\n",
    "    first_user = f\"<<SYS>>{system_prompt}<</SYS>>\\n\\n{user_text}\"\n",
    "    msgs.append({\"role\": \"user\", \"content\": first_user})\n",
    "\n",
    "    rendered = tokenizer.apply_chat_template(\n",
    "        msgs + [{\"role\": \"assistant\", \"content\": \"\"}],\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "    return {\"text\": rendered}\n",
    "\n",
    "\n",
    "def plain_format_map_fn(\n",
    "    ex: Dict[str, Any],\n",
    "    training_prompt: str,\n",
    ") -> Dict[str, str]:\n",
    "    \"\"\"Map a row into plain text (no chat template) for SFT.\"\"\"\n",
    "    vals = {\n",
    "        \"Drug\": ex.get(\"Drug\", \"\"),\n",
    "        \"Receptor\": ex.get(\"Receptor\", \"\"),\n",
    "        \"Disease\": ex.get(\"Disease\", \"\"),\n",
    "        \"report\": ex.get(\"report\", \"\"),\n",
    "        \"PDB_ID\": ex.get(\"PDB_ID\", \"\"),\n",
    "    }\n",
    "    text = training_prompt.format_map(SafeDict(vals))\n",
    "    return {\"text\": text}\n",
    "\n",
    "\n",
    "def build_dataset(\n",
    "    csv_path: str,\n",
    "    tokenizer: AutoTokenizer,\n",
    "    params: Dict[str, Any],\n",
    "    prompts: Dict[str, Any],\n",
    ") -> Dataset:\n",
    "    df = load_dataframe(csv_path)\n",
    "\n",
    "    training_prompt = prompts[\"prompts\"][\"train_user_template\"]\n",
    "    system_prompt = prompts[\"prompts\"][\"system\"]\n",
    "    use_chat_format = prompts.get(\"use_chat_format\", False)\n",
    "    few_shots = prompts.get(\"few_shots\", [])\n",
    "\n",
    "    cols = list(df.columns)\n",
    "    ds = Dataset.from_pandas(df, preserve_index=False)\n",
    "\n",
    "    if use_chat_format:\n",
    "        # HuggingFace Datasets map passes only the example dict, so we wrap\n",
    "        # our extra arguments using a closure-like helper via kwargs.\n",
    "        def _wrapped_chat_map_fn(ex: Dict[str, Any]) -> Dict[str, str]:\n",
    "            return chat_format_map_fn(\n",
    "                ex=ex,\n",
    "                training_prompt=training_prompt,\n",
    "                system_prompt=system_prompt,\n",
    "                few_shots=few_shots,\n",
    "                tokenizer=tokenizer,\n",
    "            )\n",
    "\n",
    "        ds = ds.map(_wrapped_chat_map_fn, remove_columns=cols)\n",
    "    else:\n",
    "        def _wrapped_plain_map_fn(ex: Dict[str, Any]) -> Dict[str, str]:\n",
    "            return plain_format_map_fn(\n",
    "                ex=ex,\n",
    "                training_prompt=training_prompt,\n",
    "            )\n",
    "\n",
    "        ds = ds.map(_wrapped_plain_map_fn, remove_columns=cols)\n",
    "\n",
    "    ds = ds.train_test_split(\n",
    "        test_size=params[\"data\"][\"test_size\"],\n",
    "        seed=params[\"data\"][\"seed\"],\n",
    "    )\n",
    "    return ds\n",
    "\n",
    "\n",
    "\n",
    "def get_model_and_tokenizer(params):\n",
    "    model_id = params[\"model\"][\"id\"]\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_id,\n",
    "        use_fast=True,\n",
    "        trust_remote_code=params[\"model\"].get(\"trust_remote_code\", True),\n",
    "    )\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    # bitsandbytes / QLoRA config\n",
    "    bnb_cfg = None\n",
    "    if params[\"model\"].get(\"load_in_4bit\", False):\n",
    "        bnb_cfg = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type=params[\"bnb\"][\"quant_type\"],\n",
    "            bnb_4bit_use_double_quant=params[\"bnb\"][\"double_quant\"],\n",
    "            bnb_4bit_compute_dtype=_dtype_from_str(params[\"bnb\"][\"compute_dtype\"]) or torch.float16,\n",
    "        )\n",
    "\n",
    "    # normalize max_memory from YAML\n",
    "    max_memory = _normalize_max_memory(params[\"model\"].get(\"max_memory\"))\n",
    "\n",
    "    # use dtype (new API) instead of torch_dtype\n",
    "    dtype = _dtype_from_str(params[\"model\"].get(\"dtype\"))\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        quantization_config=bnb_cfg,\n",
    "        device_map=\"auto\",\n",
    "        dtype=dtype,                           \n",
    "        max_memory=max_memory,\n",
    "        offload_folder=params[\"model\"][\"offload_folder\"],\n",
    "        low_cpu_mem_usage=True,\n",
    "        trust_remote_code=params[\"model\"][\"trust_remote_code\"],\n",
    "    )\n",
    "\n",
    "    model.config.use_cache = False\n",
    "    model.gradient_checkpointing_enable()\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "def get_lora_wrapped(model, params: Dict[str, Any]):\n",
    "    lconf = params[\"lora\"]\n",
    "    lora_cfg = LoraConfig(\n",
    "        task_type=TaskType.CAUSAL_LM,\n",
    "        r=lconf[\"r\"],\n",
    "        lora_alpha=lconf[\"alpha\"],\n",
    "        lora_dropout=lconf[\"dropout\"],\n",
    "        target_modules=lconf[\"target_modules\"],\n",
    "        bias=lconf[\"bias\"],\n",
    "    )\n",
    "    model = get_peft_model(model, lora_cfg)\n",
    "    return model\n",
    "\n",
    "\n",
    "def main(\n",
    "    train_csv: str,\n",
    "    file_paths: Dict[str, Any],\n",
    "    PARAMS: Dict[str, Any],\n",
    "    prompts: Dict[str, Any],\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Run SFT training.\n",
    "\n",
    "    Args:\n",
    "        train_csv: Path to the training CSV.\n",
    "        file_paths: Config dict from P3-config.yaml (if you need more paths).\n",
    "        params: Training hyperparameters and model settings.\n",
    "        prompts: Prompt templates and chat-format toggles.\n",
    "    \"\"\"\n",
    "    model, tokenizer = get_model_and_tokenizer()\n",
    "    model = get_lora_wrapped(model)\n",
    "\n",
    "    ds = build_dataset(train_csv, tokenizer, PARAMS, prompts)\n",
    "\n",
    "\n",
    "    # max_len = PARAMS[\"data\"][\"max_seq_length\"]\n",
    "\n",
    "    training_args = SFTConfig(\n",
    "        output_dir=PARAMS[\"model\"][\"output_dir\"],\n",
    "        num_train_epochs=PARAMS[\"train\"][\"epochs\"],\n",
    "        per_device_train_batch_size=PARAMS[\"train\"][\"per_device_train_batch_size\"],\n",
    "        per_device_eval_batch_size=PARAMS[\"train\"][\"per_device_eval_batch_size\"],\n",
    "        gradient_accumulation_steps=PARAMS[\"train\"][\"gradient_accumulation_steps\"],\n",
    "        learning_rate=PARAMS[\"train\"][\"learning_rate\"],\n",
    "        lr_scheduler_type=PARAMS[\"train\"][\"scheduler\"],\n",
    "        warmup_ratio=PARAMS[\"train\"][\"warmup_ratio\"],\n",
    "        weight_decay=PARAMS[\"train\"][\"weight_decay\"],\n",
    "        logging_steps=PARAMS[\"train\"][\"logging_steps\"],\n",
    "        eval_strategy=PARAMS[\"train\"][\"evaluation_strategy\"],   # <- NEW (replaces evaluation_strategy)\n",
    "        eval_steps=PARAMS[\"train\"][\"eval_steps\"],\n",
    "        save_steps=PARAMS[\"train\"][\"save_steps\"],\n",
    "        save_total_limit=PARAMS[\"train\"][\"save_total_limit\"],\n",
    "        bf16=PARAMS[\"train\"][\"bf16\"],\n",
    "        fp16=PARAMS[\"train\"][\"fp16\"],\n",
    "        gradient_checkpointing=PARAMS[\"train\"][\"gradient_checkpointing\"],\n",
    "        gradient_checkpointing_kwargs={\"use_reentrant\": False}, # <- NEW to silence Torch 2.5 warning\n",
    "        packing=PARAMS[\"data\"][\"packing\"],\n",
    "        optim=PARAMS[\"train\"][\"optim\"],\n",
    "        max_grad_norm=PARAMS[\"train\"][\"max_grad_norm\"],\n",
    "        seed=PARAMS[\"train\"][\"seed\"],\n",
    "        report_to=PARAMS[\"train\"][\"report_to\"],\n",
    "        load_best_model_at_end=PARAMS[\"train\"][\"load_best_model\"],\n",
    "    \n",
    "        # Move these here (don’t pass them to SFTTrainer):\n",
    "        max_seq_length=PARAMS[\"data\"][\"max_seq_length\"],\n",
    "        dataset_text_field=\"text\",\n",
    "    )\n",
    "\n",
    "        \n",
    "    early_stopping = EarlyStoppingCallback(\n",
    "        early_stopping_patience=1,      # VERY small because only 3 epochs\n",
    "        early_stopping_threshold=0.0\n",
    "    )\n",
    "\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        train_dataset=ds[\"train\"],\n",
    "        args=training_args,         # <- contains max_seq_length + dataset_text_field\n",
    "        callbacks=[early_stopping],\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "    trainer.train()\n",
    "    trainer.save_model()\n",
    "    tokenizer.save_pretrained(PARAMS[\"model\"][\"output_dir\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d9c7ef54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f54c016d90244629b5759528a30b642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/54 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "SFTConfig.__init__() got an unexpected keyword argument 'max_seq_length'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[125], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Default to train_path from config, but you can pass any CSV you want\u001b[39;00m\n\u001b[1;32m      9\u001b[0m train_csv_path \u001b[38;5;241m=\u001b[39m file_paths[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_val_paths\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_path\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 11\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_csv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_csv_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPARAMS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[124], line 230\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(train_csv, file_paths, params, prompts)\u001b[0m\n\u001b[1;32m    226\u001b[0m model \u001b[38;5;241m=\u001b[39m get_lora_wrapped(model, params)\n\u001b[1;32m    228\u001b[0m ds \u001b[38;5;241m=\u001b[39m build_dataset(train_csv, tokenizer, params, prompts)\n\u001b[0;32m--> 230\u001b[0m training_args \u001b[38;5;241m=\u001b[39m \u001b[43mSFTConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_dir\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mper_device_train_batch_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mper_device_eval_batch_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_accumulation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgradient_accumulation_steps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr_scheduler_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscheduler\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarmup_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwarmup_ratio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogging_steps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevaluation_strategy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# ✅ renamed here\u001b[39;49;00m\n\u001b[1;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_steps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msave_steps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_total_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msave_total_limit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbf16\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbf16\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfp16\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfp16\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_checkpointing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgradient_checkpointing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_checkpointing_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muse_reentrant\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpacking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpacking\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptim\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_grad_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_grad_norm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreport_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreport_to\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_best_model_at_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mload_best_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_seq_length\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_text_field\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStoppingCallback(\n\u001b[1;32m    260\u001b[0m     early_stopping_patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,      \u001b[38;5;66;03m# small because only a few epochs\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     early_stopping_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m    262\u001b[0m )\n\u001b[1;32m    264\u001b[0m trainer \u001b[38;5;241m=\u001b[39m SFTTrainer(\n\u001b[1;32m    265\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    266\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    270\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[early_stopping],\n\u001b[1;32m    271\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: SFTConfig.__init__() got an unexpected keyword argument 'max_seq_length'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load configs from YAML\n",
    "    file_paths = load_config(yaml_path=\"P3-config.yaml\")\n",
    "    PARAMS = load_config(yaml_path=\"training_params.yaml\")\n",
    "    prompts = load_config(yaml_path=\"prompts.yaml\")\n",
    "\n",
    "\n",
    "    # Default to train_path from config, but you can pass any CSV you want\n",
    "    train_csv_path = file_paths[\"train_val_paths\"][\"train_path\"]\n",
    "\n",
    "    main(\n",
    "        train_csv=train_csv_path,\n",
    "        file_paths=file_paths,\n",
    "        params=PARAMS,\n",
    "        prompts=prompts,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722342be-d1f1-4c6d-b1f9-7ef38a86eaae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fypkernel2",
   "language": "python",
   "name": "fyp_kernel2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
