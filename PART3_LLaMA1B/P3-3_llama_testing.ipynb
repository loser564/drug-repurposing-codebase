{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "042b2f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Standard Library\n",
    "# ================================\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "# ================================\n",
    "# Third-Party Libraries\n",
    "# ================================\n",
    "import bitsandbytes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "# HuggingFace Transformers\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    EarlyStoppingCallback,\n",
    "    GenerationConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    __version__ as HF_VER,\n",
    ")\n",
    "\n",
    "# PEFT (LoRA / QLoRA)\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftModel,\n",
    "    TaskType,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    ")\n",
    "\n",
    "# TRL (Supervised Fine-Tuning Trainer)\n",
    "from trl import SFTConfig, SFTTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4e73b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(yaml_path):\n",
    "    with open(yaml_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "    \n",
    "file_paths = load_config(yaml_path=\"P3-config.yaml\")\n",
    "PARAMS = load_config(yaml_path=\"validation_params.yaml\")\n",
    "prompts = load_config(yaml_path=\"prompts.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d5ea3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drug</th>\n",
       "      <th>Receptor</th>\n",
       "      <th>PDB_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Metformin</td>\n",
       "      <td>Acetyl-CoA carboxylase 2</td>\n",
       "      <td>3FF6,3TDC,2X24,3JRX,3JRW,2HJW,4HQ6,5KKN,3GLK,3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pioglitazone</td>\n",
       "      <td>Peroxisome proliferator-activated receptor gamma</td>\n",
       "      <td>3E00,3DZY,3DZU,7QB1,6L89,6K0T,6AD9,5HZC,5F9B,5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alogliptin</td>\n",
       "      <td>Dipeptidyl peptidase 4</td>\n",
       "      <td>2QTB,2QT9,2BGR,2JID,3F8S,2QJR,3W2T,3VJM,3VJL,3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linagliptin</td>\n",
       "      <td>Dipeptidyl peptidase 4</td>\n",
       "      <td>2QTB,2QT9,2BGR,2JID,3F8S,2QJR,3W2T,3VJM,3VJL,3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sitagliptin</td>\n",
       "      <td>Dipeptidyl peptidase 4</td>\n",
       "      <td>2QTB,2QT9,2BGR,2JID,3F8S,2QJR,3W2T,3VJM,3VJL,3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Saxagliptin</td>\n",
       "      <td>Dipeptidyl peptidase 4</td>\n",
       "      <td>2QTB,2QT9,2BGR,2JID,3F8S,2QJR,3W2T,3VJM,3VJL,3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vildagliptin</td>\n",
       "      <td>Dipeptidyl peptidase 4</td>\n",
       "      <td>2QTB,2QT9,2BGR,2JID,3F8S,2QJR,3W2T,3VJM,3VJL,3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bromocriptine</td>\n",
       "      <td>Dopamine D2 receptor</td>\n",
       "      <td>8IRS,7JVR,8U02,8TZQ,6VMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Canagliflozin</td>\n",
       "      <td>Sodium/glucose cotransporter 2</td>\n",
       "      <td>7YNK,7YNJ,7VSI,8HIN,8HG7,8HEZ,8HDH,8HB0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dapagliflozin</td>\n",
       "      <td>Sodium/glucose cotransporter 2</td>\n",
       "      <td>7YNK,7YNJ,7VSI,8HIN,8HG7,8HEZ,8HDH,8HB0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Empagliflozin</td>\n",
       "      <td>Sodium/glucose cotransporter 2</td>\n",
       "      <td>7YNK,7YNJ,7VSI,8HIN,8HG7,8HEZ,8HDH,8HB0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Semaglutide</td>\n",
       "      <td>Glucagon-like peptide 1 receptor</td>\n",
       "      <td>7FIM,7RTB,9J1P,9IVM,9IVG,9EBQ,9EBO,9EBN,9C0K,9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Exenatide</td>\n",
       "      <td>Glucagon-like peptide 1 receptor</td>\n",
       "      <td>7FIM,7RTB,9J1P,9IVM,9IVG,9EBQ,9EBO,9EBN,9C0K,9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Liraglutide</td>\n",
       "      <td>Glucagon-like peptide 1 receptor</td>\n",
       "      <td>7FIM,7RTB,9J1P,9IVM,9IVG,9EBQ,9EBO,9EBN,9C0K,9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Albiglutide</td>\n",
       "      <td>Glucagon-like peptide 1 receptor</td>\n",
       "      <td>7FIM,7RTB,9J1P,9IVM,9IVG,9EBQ,9EBO,9EBN,9C0K,9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Dulaglutide</td>\n",
       "      <td>Glucagon-like peptide 1 receptor</td>\n",
       "      <td>7FIM,7RTB,9J1P,9IVM,9IVG,9EBQ,9EBO,9EBN,9C0K,9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Lixisenatide</td>\n",
       "      <td>Glucagon-like peptide 1 receptor</td>\n",
       "      <td>7FIM,7RTB,9J1P,9IVM,9IVG,9EBQ,9EBO,9EBN,9C0K,9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Tirzepatide</td>\n",
       "      <td>Glucagon-like peptide 1 receptor</td>\n",
       "      <td>7FIM,7RTB,9J1P,9IVM,9IVG,9EBQ,9EBO,9EBN,9C0K,9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Pramlintide</td>\n",
       "      <td>Glucagon-like peptide 1 receptor</td>\n",
       "      <td>7FIM,7RTB,9J1P,9IVM,9IVG,9EBQ,9EBO,9EBN,9C0K,9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Human regular</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Rosiglitazone</td>\n",
       "      <td>Peroxisome proliferator-activated receptor gamma</td>\n",
       "      <td>3E00,3DZY,3DZU,7QB1,6L89,6K0T,6AD9,5HZC,5F9B,5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Selegiline</td>\n",
       "      <td>Substance-P receptor</td>\n",
       "      <td>8U26,7RMI,7RMH,7RMG,2KSB,2KSA,2KS9,7P02,7P00,6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Lorazepam</td>\n",
       "      <td>Translocator protein</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Alprazolam</td>\n",
       "      <td>Translocator protein</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Paroxetine</td>\n",
       "      <td>Serotonin transporter</td>\n",
       "      <td>6VRL,6VRK,6VRH,7TXT,7LWD,5I6Z,6W2C,6W2B,6DZZ,6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Escitalopram</td>\n",
       "      <td>Serotonin transporter</td>\n",
       "      <td>6VRL,6VRK,6VRH,7TXT,7LWD,5I6Z,6W2C,6W2B,6DZZ,6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Sertraline</td>\n",
       "      <td>Serotonin transporter</td>\n",
       "      <td>6VRL,6VRK,6VRH,7TXT,7LWD,5I6Z,6W2C,6W2B,6DZZ,6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Fluoxetine</td>\n",
       "      <td>Serotonin transporter</td>\n",
       "      <td>6VRL,6VRK,6VRH,7TXT,7LWD,5I6Z,6W2C,6W2B,6DZZ,6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Selegiline</td>\n",
       "      <td>Monoamine oxidase type B</td>\n",
       "      <td>9FJT,7ZW3,7P4H,7P4F,7B0Z,7B0V,6RLE,6RKP,6RKB,6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Drug                                          Receptor  \\\n",
       "0       Metformin                          Acetyl-CoA carboxylase 2   \n",
       "1    Pioglitazone  Peroxisome proliferator-activated receptor gamma   \n",
       "2      Alogliptin                            Dipeptidyl peptidase 4   \n",
       "3     Linagliptin                            Dipeptidyl peptidase 4   \n",
       "4     Sitagliptin                            Dipeptidyl peptidase 4   \n",
       "5     Saxagliptin                            Dipeptidyl peptidase 4   \n",
       "6    Vildagliptin                            Dipeptidyl peptidase 4   \n",
       "7   Bromocriptine                              Dopamine D2 receptor   \n",
       "8   Canagliflozin                    Sodium/glucose cotransporter 2   \n",
       "9   Dapagliflozin                    Sodium/glucose cotransporter 2   \n",
       "10  Empagliflozin                    Sodium/glucose cotransporter 2   \n",
       "11    Semaglutide                  Glucagon-like peptide 1 receptor   \n",
       "12      Exenatide                  Glucagon-like peptide 1 receptor   \n",
       "13    Liraglutide                  Glucagon-like peptide 1 receptor   \n",
       "14    Albiglutide                  Glucagon-like peptide 1 receptor   \n",
       "15    Dulaglutide                  Glucagon-like peptide 1 receptor   \n",
       "16   Lixisenatide                  Glucagon-like peptide 1 receptor   \n",
       "17    Tirzepatide                  Glucagon-like peptide 1 receptor   \n",
       "18    Pramlintide                  Glucagon-like peptide 1 receptor   \n",
       "19  Human regular                                               NaN   \n",
       "20  Rosiglitazone  Peroxisome proliferator-activated receptor gamma   \n",
       "21     Selegiline                              Substance-P receptor   \n",
       "22      Lorazepam                              Translocator protein   \n",
       "23     Alprazolam                              Translocator protein   \n",
       "24     Paroxetine                             Serotonin transporter   \n",
       "25   Escitalopram                             Serotonin transporter   \n",
       "26     Sertraline                             Serotonin transporter   \n",
       "27     Fluoxetine                             Serotonin transporter   \n",
       "28     Selegiline                          Monoamine oxidase type B   \n",
       "\n",
       "                                               PDB_ID  \n",
       "0   3FF6,3TDC,2X24,3JRX,3JRW,2HJW,4HQ6,5KKN,3GLK,3...  \n",
       "1   3E00,3DZY,3DZU,7QB1,6L89,6K0T,6AD9,5HZC,5F9B,5...  \n",
       "2   2QTB,2QT9,2BGR,2JID,3F8S,2QJR,3W2T,3VJM,3VJL,3...  \n",
       "3   2QTB,2QT9,2BGR,2JID,3F8S,2QJR,3W2T,3VJM,3VJL,3...  \n",
       "4   2QTB,2QT9,2BGR,2JID,3F8S,2QJR,3W2T,3VJM,3VJL,3...  \n",
       "5   2QTB,2QT9,2BGR,2JID,3F8S,2QJR,3W2T,3VJM,3VJL,3...  \n",
       "6   2QTB,2QT9,2BGR,2JID,3F8S,2QJR,3W2T,3VJM,3VJL,3...  \n",
       "7                            8IRS,7JVR,8U02,8TZQ,6VMS  \n",
       "8             7YNK,7YNJ,7VSI,8HIN,8HG7,8HEZ,8HDH,8HB0  \n",
       "9             7YNK,7YNJ,7VSI,8HIN,8HG7,8HEZ,8HDH,8HB0  \n",
       "10            7YNK,7YNJ,7VSI,8HIN,8HG7,8HEZ,8HDH,8HB0  \n",
       "11  7FIM,7RTB,9J1P,9IVM,9IVG,9EBQ,9EBO,9EBN,9C0K,9...  \n",
       "12  7FIM,7RTB,9J1P,9IVM,9IVG,9EBQ,9EBO,9EBN,9C0K,9...  \n",
       "13  7FIM,7RTB,9J1P,9IVM,9IVG,9EBQ,9EBO,9EBN,9C0K,9...  \n",
       "14  7FIM,7RTB,9J1P,9IVM,9IVG,9EBQ,9EBO,9EBN,9C0K,9...  \n",
       "15  7FIM,7RTB,9J1P,9IVM,9IVG,9EBQ,9EBO,9EBN,9C0K,9...  \n",
       "16  7FIM,7RTB,9J1P,9IVM,9IVG,9EBQ,9EBO,9EBN,9C0K,9...  \n",
       "17  7FIM,7RTB,9J1P,9IVM,9IVG,9EBQ,9EBO,9EBN,9C0K,9...  \n",
       "18  7FIM,7RTB,9J1P,9IVM,9IVG,9EBQ,9EBO,9EBN,9C0K,9...  \n",
       "19                                                NaN  \n",
       "20  3E00,3DZY,3DZU,7QB1,6L89,6K0T,6AD9,5HZC,5F9B,5...  \n",
       "21  8U26,7RMI,7RMH,7RMG,2KSB,2KSA,2KS9,7P02,7P00,6...  \n",
       "22                                                NaN  \n",
       "23                                                NaN  \n",
       "24  6VRL,6VRK,6VRH,7TXT,7LWD,5I6Z,6W2C,6W2B,6DZZ,6...  \n",
       "25  6VRL,6VRK,6VRH,7TXT,7LWD,5I6Z,6W2C,6W2B,6DZZ,6...  \n",
       "26  6VRL,6VRK,6VRH,7TXT,7LWD,5I6Z,6W2C,6W2B,6DZZ,6...  \n",
       "27  6VRL,6VRK,6VRH,7TXT,7LWD,5I6Z,6W2C,6W2B,6DZZ,6...  \n",
       "28  9FJT,7ZW3,7P4H,7P4F,7B0Z,7B0V,6RLE,6RKP,6RKB,6...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_path = file_paths['test_paths']['test_path']\n",
    "test_df = pd.read_csv(test_df_path)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "064131d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _dtype_from_str(s: str):\n",
    "    s = (s or \"\").lower()\n",
    "    if s in (\"bf16\", \"bfloat16\"):\n",
    "        return torch.bfloat16\n",
    "    if s in (\"fp16\", \"float16\", \"half\"):\n",
    "        return torch.float16\n",
    "    if s in (\"fp32\", \"float32\"):\n",
    "        return torch.float32\n",
    "    return torch.float16\n",
    "\n",
    "\n",
    "def make_bnb_config(infer_cfg: Dict[str, Any]) -> BitsAndBytesConfig:\n",
    "    \"\"\"\n",
    "    Build BitsAndBytesConfig from validation_params.yaml's `quantization` block.\n",
    "    \"\"\"\n",
    "    q = infer_cfg[\"quantization\"]\n",
    "    compute_dtype = q.get(\"compute_dtype\", \"auto\")\n",
    "\n",
    "    # allow \"auto\" in YAML, resolve here\n",
    "    if compute_dtype == \"auto\":\n",
    "        compute_dtype = \"bf16\" if torch.cuda.is_bf16_supported() else \"fp16\"\n",
    "\n",
    "    return BitsAndBytesConfig(\n",
    "        load_in_4bit=q[\"load_in_4bit\"],\n",
    "        bnb_4bit_quant_type=q[\"quant_type\"],\n",
    "        bnb_4bit_use_double_quant=q[\"double_quant\"],\n",
    "        bnb_4bit_compute_dtype=_dtype_from_str(compute_dtype),\n",
    "    )\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Model loading\n",
    "# -------------------------------\n",
    "\n",
    "def load_model_and_tokenizer_for_inference(\n",
    "    infer_cfg: Dict[str, Any]\n",
    "):\n",
    "    \"\"\"\n",
    "    Load base model + LoRA adapter for inference.\n",
    "\n",
    "    Uses:\n",
    "      - 4-bit quantization (preferred) OR\n",
    "      - merged 16-bit model if `merge_16bit` is True.\n",
    "    \"\"\"\n",
    "    base_id = infer_cfg[\"base_model_id\"]\n",
    "    adapter_dir = infer_cfg[\"adapter_dir\"]\n",
    "    device_map = infer_cfg[\"batch\"][\"device_map\"]\n",
    "    merge_16bit = infer_cfg[\"merge_16bit\"]\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        base_id,\n",
    "        use_fast=True,\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"right\"\n",
    "\n",
    "    if merge_16bit:\n",
    "        # 16-bit merged model\n",
    "        dtype = torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            base_id,\n",
    "            device_map=device_map,\n",
    "            torch_dtype=dtype,\n",
    "            trust_remote_code=True,\n",
    "        )\n",
    "        model = PeftModel.from_pretrained(model, adapter_dir)\n",
    "        model = model.merge_and_unload()\n",
    "    else:\n",
    "        # 4-bit quantized path\n",
    "        bnb_cfg = make_bnb_config(infer_cfg)\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            base_id,\n",
    "            quantization_config=bnb_cfg,\n",
    "            device_map=device_map,\n",
    "            trust_remote_code=True,\n",
    "        )\n",
    "        model = PeftModel.from_pretrained(model, adapter_dir)\n",
    "\n",
    "    model.eval()\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Prompt composition\n",
    "# -------------------------------\n",
    "\n",
    "\n",
    "PLACEHOLDER_RE = re.compile(r\"\\{([A-Za-z0-9_]+)\\}\")\n",
    "\n",
    "def render_template_safe(template: str, values: Dict[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    Replace {Key} placeholders using a regex, leaving all other braces intact.\n",
    "    This prevents JSON examples like { \"a\": 1 } from being treated as format fields\n",
    "    because we do NOT call .format().\n",
    "    Only patterns that look like {WordLikeKey} are replaced.\n",
    "    \"\"\"\n",
    "    def repl(m):\n",
    "        key = m.group(1)\n",
    "        v = values.get(key, \"\")\n",
    "        return \"\" if v is None else str(v)\n",
    "    return PLACEHOLDER_RE.sub(repl, template or \"\")\n",
    "\n",
    "\n",
    "def compose_chat_prompt_llama32(\n",
    "    system_prompt: str,\n",
    "    user_template: str,\n",
    "    values: Dict[str, Any],\n",
    "    tokenizer,\n",
    "    few_shots: Optional[List[Dict[str, str]]] = None,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Llama-3.2 Instruct chat formatting:\n",
    "    - system message is its own role\n",
    "    - user message contains rendered template text\n",
    "    - apply_chat_template handles <|begin_of_text|> etc\n",
    "    \"\"\"\n",
    "    user_text = render_template_safe(user_template, values)\n",
    "\n",
    "    msgs: List[Dict[str, str]] = []\n",
    "    if system_prompt and str(system_prompt).strip():\n",
    "        msgs.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "\n",
    "    # Optional few-shot examples (same structure as your training config)\n",
    "    for shot in few_shots or []:\n",
    "        if shot and \"user\" in shot and \"assistant\" in shot:\n",
    "            msgs.append({\"role\": \"user\", \"content\": shot[\"user\"]})\n",
    "            msgs.append({\"role\": \"assistant\", \"content\": shot[\"assistant\"]})\n",
    "\n",
    "    msgs.append({\"role\": \"user\", \"content\": user_text})\n",
    "\n",
    "    # For inference, we want the assistant header/prefix to be appended\n",
    "    return tokenizer.apply_chat_template(\n",
    "        msgs,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "\n",
    "\n",
    "def compose_plain_prompt_safe(\n",
    "    user_template: str,\n",
    "    values: Dict[str, Any],\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Plain prompt version that is also JSON-brace-safe.\n",
    "    \"\"\"\n",
    "    return render_template_safe(user_template, values)\n",
    "# -------------------------------\n",
    "# Row-level generation\n",
    "# -------------------------------\n",
    "def select_user_template(p_cfg: Dict[str, Any], test: bool, tier: str) -> str:\n",
    "    \"\"\"\n",
    "    tier: one of {\"basic\", \"oncologist\", \"reviewer\"} for test.\n",
    "    For validation we ignore tier and use val_user_template.\n",
    "    \"\"\"\n",
    "    if not test:\n",
    "        return p_cfg[\"val_user_template\"]\n",
    "\n",
    "    # test mode\n",
    "    if tier == \"basic\":\n",
    "        return p_cfg[\"test_user_template\"]\n",
    "    if tier == \"oncologist\":\n",
    "        return p_cfg[\"test_user_template_oncologist\"]\n",
    "    if tier == \"reviewer\":\n",
    "        return p_cfg[\"test_user_template_reviewer\"]\n",
    "\n",
    "    raise ValueError(f\"Unknown prompt tier: {tier}\")\n",
    "    \n",
    "@torch.no_grad()\n",
    "def generate_for_row(\n",
    "    row: Dict[str, Any],\n",
    "    model,\n",
    "    tokenizer,\n",
    "    infer_cfg: Dict[str, Any],\n",
    "    prompts_cfg: Dict[str, Any],\n",
    "    test: bool,\n",
    "    tier: str\n",
    ") -> str:\n",
    "    col_cfg = infer_cfg[\"columns\"]\n",
    "    col_d = col_cfg[\"drug\"]\n",
    "    col_r = col_cfg[\"receptor\"]\n",
    "    col_p = col_cfg[\"pdb\"]\n",
    "    col_rep = col_cfg.get(\"report\")  # OPTIONAL: add this in your validation_params.yaml if you have report\n",
    "\n",
    "    drug = str(row.get(col_d, \"\") or \"\")\n",
    "    receptor = str(row.get(col_r, \"\") or \"\")\n",
    "\n",
    "    pdb_raw = str(row.get(col_p, \"\") or \"\")\n",
    "    pdb_ids = \",\".join([p.strip() for p in pdb_raw.split(\",\") if p.strip()]) if pdb_raw else \"\"\n",
    "\n",
    "    report = \"\"\n",
    "    if col_rep:\n",
    "        report = str(row.get(col_rep, \"\") or \"\")\n",
    "\n",
    "    p_cfg = prompts_cfg.get(\"prompts\", prompts_cfg)\n",
    "    use_chat_format = p_cfg.get(\"use_chat_format\", False)\n",
    "    system_prompt = p_cfg.get(\"system\", \"\")\n",
    "    few_shots = p_cfg.get(\"few_shots\", [])\n",
    "\n",
    "    # Pick the right template for validation vs test\n",
    "    user_template = select_user_template(p_cfg, test=test, tier=tier)\n",
    "\n",
    "\n",
    "    values = {\n",
    "        \"Drug\": drug,\n",
    "        \"Receptor\": receptor,\n",
    "        \"PDB_ID\": pdb_ids,\n",
    "        \"report\": report,   # IMPORTANT: supports {report} in templates\n",
    "    }\n",
    "\n",
    "    if use_chat_format:\n",
    "        prompt = compose_chat_prompt_llama32(\n",
    "            system_prompt=system_prompt,\n",
    "            user_template=user_template,\n",
    "            values=values,\n",
    "            tokenizer=tokenizer,\n",
    "            few_shots=few_shots,\n",
    "        )\n",
    "    else:\n",
    "        prompt = compose_plain_prompt_safe(\n",
    "            user_template=user_template,\n",
    "            values=values,\n",
    "        )\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        add_special_tokens=False,\n",
    "    )\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "    gen_cfg = infer_cfg[\"generation\"]\n",
    "    out = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=gen_cfg[\"max_new_tokens\"],\n",
    "        do_sample=gen_cfg[\"do_sample\"],\n",
    "        temperature=gen_cfg[\"temperature\"],\n",
    "        top_p=gen_cfg[\"top_p\"],\n",
    "        top_k=gen_cfg[\"top_k\"],\n",
    "        repetition_penalty=gen_cfg[\"repetition_penalty\"],\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "    )\n",
    "\n",
    "    generated = out[0][inputs[\"input_ids\"].shape[1]:]\n",
    "    text = tokenizer.decode(generated, skip_special_tokens=True)\n",
    "\n",
    "    for s in gen_cfg.get(\"stop_strings\", []):\n",
    "        if s and s in text:\n",
    "            text = text.split(s)[0].rstrip()\n",
    "            break\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Output path helper\n",
    "# -------------------------------\n",
    "\n",
    "def get_output_path(\n",
    "    infer_cfg: Dict[str, Any],\n",
    "    test: bool,\n",
    "    category: str,\n",
    "    real_world: bool,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Decide which CSV path to save to based on flags.\n",
    "    Uses the `save_paths` block from validation_params.yaml.\n",
    "    \"\"\"\n",
    "    paths = infer_cfg[\"save_paths\"]\n",
    "\n",
    "    if not test:\n",
    "        return paths[\"inference_reports\"]\n",
    "\n",
    "    if real_world:\n",
    "        if category==\"basic\":\n",
    "            return paths[\"real_world_test_basic\"]\n",
    "        elif category==\"oncologist\":\n",
    "            return paths[\"real_world_test_onco\"]\n",
    "        elif category==\"reviewer\":\n",
    "            return paths[\"real_world_test_review\"]\n",
    "\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# DataFrame-level inference\n",
    "# -------------------------------\n",
    "\n",
    "def run_inference(\n",
    "    df: pd.DataFrame,\n",
    "    model,\n",
    "    tokenizer,\n",
    "    infer_cfg: Dict[str, Any],\n",
    "    prompts_cfg: Dict[str, Any],\n",
    "    test: bool,\n",
    "    relation: bool,\n",
    "    real_world: bool,\n",
    "    tier: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Run inference over all rows in a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df: Input examples (must contain columns specified in infer_cfg[\"columns\"]).\n",
    "        model, tokenizer: Loaded via `load_model_and_tokenizer_for_inference`.\n",
    "        infer_cfg: validation_params.yaml contents.\n",
    "        prompts_cfg: prompts.yaml contents.\n",
    "        test: If False => validation-like set; if True => test scenarios.\n",
    "        relation: If True (and test=True), saves to \"some_relation\" path.\n",
    "        real_world: If True (and test=True), saves to \"real_world_test\" path.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with an extra column `generated_report`.\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    for _, row in df.iterrows():\n",
    "        report = generate_for_row(\n",
    "            row=row.to_dict(),\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            infer_cfg=infer_cfg,\n",
    "            prompts_cfg=prompts_cfg,\n",
    "            test=test,\n",
    "            tier=tier,\n",
    "        )\n",
    "        rec = dict(row)\n",
    "        rec[\"generated_report\"] = report\n",
    "        rec[\"prompt_tier\"] = tier\n",
    "        records.append(rec)\n",
    "\n",
    "    out_df = pd.DataFrame(records)\n",
    "    out_path = get_output_path(\n",
    "        infer_cfg=infer_cfg,\n",
    "        test=test,\n",
    "        category=tier,\n",
    "        real_world=real_world,\n",
    "    )\n",
    "    print(out_path)\n",
    "    out_path.replace(\".csv\", f\"_{tier}.csv\")\n",
    "    out_df.to_csv(out_path, index=False)\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e2ba7c",
   "metadata": {},
   "source": [
    "## basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f24a8bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama_1b_basic_realworldtest.csv\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = load_model_and_tokenizer_for_inference(PARAMS)\n",
    "test_outputs = run_inference(\n",
    "    df=test_df,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    infer_cfg=PARAMS,\n",
    "    prompts_cfg=prompts,\n",
    "    test=True,\n",
    "    relation=False,\n",
    "    real_world=True,\n",
    "    tier=\"basic\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3f16b5",
   "metadata": {},
   "source": [
    "## onco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70622548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama_1b_onco_realworldtest.csv\n"
     ]
    }
   ],
   "source": [
    "test_outputs = run_inference(\n",
    "    df=test_df,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    infer_cfg=PARAMS,\n",
    "    prompts_cfg=prompts,\n",
    "    test=True,\n",
    "    relation=False,\n",
    "    real_world=True,\n",
    "    tier=\"oncologist\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1a1f6a",
   "metadata": {},
   "source": [
    "## review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc5514c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama_1b_review_realworldtest.csv\n"
     ]
    }
   ],
   "source": [
    "test_outputs = run_inference(\n",
    "    df=test_df,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    infer_cfg=PARAMS,\n",
    "    prompts_cfg=prompts,\n",
    "    test=True,\n",
    "    relation=False,\n",
    "    real_world=True,\n",
    "    tier=\"reviewer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ca6b29-814c-41fa-88b1-0ca2032db26f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fypkernel2",
   "language": "python",
   "name": "fyp_kernel2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
